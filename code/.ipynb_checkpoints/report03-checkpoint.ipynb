{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report02 - Nathan Yee\n",
    "\n",
    "This notebook contains report03 for computational baysian statistics fall 2016\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "% matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from thinkbayes2 import Pmf, Cdf, Suite, Joint\n",
    "import thinkplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sock problem\n",
    "\n",
    "Created by Yuzhong Huang\n",
    "\n",
    "There are two drawers of socks. The first drawer has 40 white socks and 10 black socks; the second drawer has 20 white socks and 30 black socks. We randomly get 2 socks from a drawer, and it turns out to be a pair(same color) but we don't know the color of these socks. What is the chance that we picked the first drawer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make calculating our likelihood easier, we start by defining a multiply function. The function is written in a functional way primarily for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def multiply(items):\n",
    "    \"\"\"\n",
    "    multiply takes a list of numbers, multiplies all of them, and returns the result\n",
    "    \n",
    "    Args:\n",
    "        items (list): The list of numbers\n",
    "        \n",
    "    Return:\n",
    "        the items multiplied together\n",
    "    \"\"\"\n",
    "    return reduce(operator.mul, items, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a drawer suite. This suite will allow us to take n socks up to the least number of socks in a drawer. To make our likelihood function simpler, we ignore the case where we take 11 black socks and that only drawer 2 is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Drawers(Suite):\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"\n",
    "        Likelihood returns the likelihood given a bayesian update \n",
    "        consisting of a particular hypothesis and new data. In the\n",
    "        case of our drawer problem, the probabilities change with the\n",
    "        number of pairs we take (without replacement) so we we start\n",
    "        by defining lists for each color sock in each drawer.\n",
    "        \n",
    "        Args:\n",
    "            data (int): The number of socks we take\n",
    "            hypo (str): The hypothesis we are updating\n",
    "            \n",
    "        Return:\n",
    "            the likelihood for a hypothesis\n",
    "        \"\"\"\n",
    "        \n",
    "        drawer1W = []\n",
    "        drawer1B = []\n",
    "        drawer2W = []\n",
    "        drawer2B = []\n",
    "        for i in range(data):\n",
    "            drawer1W.append(40-i)\n",
    "            drawer1B.append(10-i)\n",
    "            drawer2W.append(20-i)\n",
    "            drawer2B.append(30-i)\n",
    "        \n",
    "        if hypo == 'drawer1':\n",
    "            return multiply(drawer1W)+multiply(drawer1B)\n",
    "        if hypo == 'drawer2':\n",
    "            return multiply(drawer2W)+multiply(drawer2B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define our hypotheses and create the drawer Suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawer1 0.5\n",
      "drawer2 0.5\n"
     ]
    }
   ],
   "source": [
    "hypos = ['drawer1','drawer2']\n",
    "drawers = Drawers(hypos)\n",
    "drawers.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, update the drawers by taking two matching socks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawer1 0.5689655172413792\n",
      "drawer2 0.43103448275862066\n"
     ]
    }
   ],
   "source": [
    "drawers.Update(2)\n",
    "drawers.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the drawer with many of a single sock (40 white 10 black) is more likely after the update. To confirm this suspicion, let's restart the problem by taking 5 pairs of socks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawer1 0.8064243448858833\n",
      "drawer2 0.19357565511411665\n"
     ]
    }
   ],
   "source": [
    "hypos = ['drawer1','drawer2']\n",
    "drawers5 = Drawers(hypos)\n",
    "drawers5.Update(5)\n",
    "drawers5.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that after we take 5 pairs of socks, the probability of the socks coming from drawer 1 is 80.6%. We can now conclude that the drawer with a more extreme numbers of socks is more likely be chosen if we are updating with matching color socks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chess-playing twins\n",
    "\n",
    "Allen Downey\n",
    "\n",
    "Two identical twins are members of my chess club, but they never show up on the same day; in fact, they strictly alternate the days they show up.  I can't tell them apart except that one is a better player than the other:  Avery beats me 60% of the time and I beat Blake 70% of the time.  If I play one twin on Monday and win, and the other twin on Tuesday and lose, which twin did I play on which day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, we first need to create our hypothesis. In this case, we have:  \n",
    "\n",
    "hypo1: Avery Monday, Blake Tuesday  \n",
    "hypo2: Blake Monday, Avery Tuesday  \n",
    "\n",
    "We will abreviate Avery to A and Blake to B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB 0.5\n",
      "BA 0.5\n"
     ]
    }
   ],
   "source": [
    "twins = Pmf()\n",
    "twins['AB'] = 1\n",
    "twins['BA'] = 1\n",
    "twins.Normalize()\n",
    "twins.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we update our hypotheses with us winning the first day. We have a 40% chance of winning against Avery and a 70% chance of winning against Blake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB 0.36363636363636365\n",
      "BA 0.6363636363636364\n"
     ]
    }
   ],
   "source": [
    "#win day 1\n",
    "twins['AB'] *= .4\n",
    "twins['BA'] *= .7\n",
    "twins.Normalize()\n",
    "twins.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in time, there is only a 36% chance that we play Avery the first day while a 64% chance that we played Blake the first day.\n",
    "\n",
    "However, let's see what happens when we update with a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB 0.5333333333333333\n",
      "BA 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "#lose day 2\n",
    "twins['AB'] *= .6\n",
    "twins['BA'] *= .3\n",
    "twins.Normalize()\n",
    "twins.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Now there is a 53% chance that we played Avery then Blake and a 47% chance that we played Blake then Avery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who saw that movie?\n",
    "\n",
    "Nathan Yee\n",
    "\n",
    "Every year the MPAA (Motion Picture Association of America) publishes a [report](http://www.mpaa.org/wp-content/uploads/2016/04/MPAA-Theatrical-Market-Statistics-2015_Final.pdf) about theatrical market statistics. Included in the report, are both the gender and the ethnicity share of the top 5 most grossing films. If a randomly selected person in the United States went to Pixar's \"Inside Out\", what is the probability that they are both female and Asian?\n",
    "\n",
    "Data:\n",
    "\n",
    "| Gender                      | Male (%) | Female (%)  |\n",
    "| :-------------------------- | :------- | :---------- |\n",
    "| Furious 7                   | 56       | 44          |\n",
    "| Inside Out                  | 46       | 54          |\n",
    "| Avengers: Age of Ultron     | 58       | 42          |\n",
    "| Star Wars: The Force Awakens| 58       | 42          |\n",
    "| Jurassic World              | 55       | 45          |\n",
    "\n",
    "\n",
    "| Ethnicity                   | Caucasian (%) | African-American (%) | Hispanic (%) | Asian (%) | Other (%) |\n",
    "| :-------------------------- | :------------ | :------------------- | :----------- | :-------- | :-------- |\n",
    "| Furious 7                   | 40            | 22                   | 25           | 8         | 5         |\n",
    "| Inside Out                  | 54            | 15                   | 16           | 9         | 5         |\n",
    "| Avengers: Age of Ultron     | 50            | 16                   | 20           | 10        | 5         |\n",
    "| Star Wars: The Force Awakens| 61            | 12                   | 15           | 7         | 5         |\n",
    "| Jurassic World              | 39            | 16                   | 19           | 11        | 6         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are picking a random person in the United States, we can use demographics of the United States as an informed prior.\n",
    "\n",
    "| Demographic                 | Caucasian (%) | African-American (%) | Hispanic (%) | Asian (%) | Other (%) |\n",
    "| :-------------------------- | :------------ | :------------------- | :----------- | :-------- | :-------- |\n",
    "| Population United States    | 63.7          | 12.2                 | 16.3         | 4.7       | 3.1       |\n",
    "\n",
    "Note:\n",
    "Demographic data was gathered from the US Census Bureau. There may be errors within 2% due to rounding. Also note that certian races were combined to fit our previous demographic groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make writing code easier, we will encoude data in a numerical structure. The first item in the tuple corresponds to gender, the second item in the tuple corresponds to ethnicity.\n",
    "\n",
    "| Gender                      | Male | Female |\n",
    "| :-------------------------- | :--- | :----- |\n",
    "| Encoding number             | 0    | 1      |\n",
    "\n",
    "| Ethnicity                   | Caucasian | African-American | Hispanic | Asian | Other |\n",
    "| :-------------------------- | :-------- | :--------------- | :------- | :---- | :---- |\n",
    "| Encoding number             | 0         | 1                | 2        | 3     | 4     |\n",
    "\n",
    "\n",
    "Such that a (female, asian) = (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first piece of code we write will be our Movie class. This version of Suite will have a special likelihood function that takes in a movie, and returns the probability of the gender and the ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Movie(Suite, Joint):\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"\n",
    "        Likelihood returns the likelihood given a bayesian update consisting of a particular\n",
    "        hypothesis and data. In this case, we need to calculate the probability of seeing a\n",
    "        gender seeing a movie. Then we calculat the probability that an ethnicity saw a\n",
    "        movie. Finally we multiply the two to calculate the a person of a gender and \n",
    "        ethnicity saw a movie.\n",
    "        \n",
    "        Args:\n",
    "            data (str): The title of the movie\n",
    "            hypo (str): The hypothesis we are updating\n",
    "            \n",
    "        Return:\n",
    "            the likelihood for a hypothesis\n",
    "        \"\"\"\n",
    "        \n",
    "        movie = data        \n",
    "        gender = hypo[0]\n",
    "        ethnicity = hypo[1]\n",
    "        \n",
    "        # first calculate update based on gender\n",
    "        movies_gender = {'Furious 7'                    : {0:56, 1:44},\n",
    "                         'Inside Out'                   : {0:46, 1:54},\n",
    "                         'Avengers: Age of Ultron'      : {0:58, 1:42},\n",
    "                         'Star Wars: The Force Awakens' : {0:58, 1:42},\n",
    "                         'Jurassic World'               : {0:55, 1:45}\n",
    "                         }\n",
    "        \n",
    "        like_gender = movies_gender[movie][gender]\n",
    "        \n",
    "        # second calculate update based on ethnicity\n",
    "        movies_ethnicity = {'Furious 7'                    : {0:40, 1:22, 2:25, 3:8 , 4:5},\n",
    "                            'Inside Out'                   : {0:54, 1:15, 2:16, 3:9 , 4:4},\n",
    "                            'Avengers: Age of Ultron'      : {0:50, 1:16, 2:20, 3:10, 4:5},\n",
    "                            'Star Wars: The Force Awakens' : {0:61, 1:12, 2:15, 3:7 , 4:5},\n",
    "                            'Jurassic World'               : {0:39, 1:16, 2:19, 3:11, 4:6}\n",
    "                 }\n",
    "        \n",
    "        like_ethnicity = movies_ethnicity[movie][ethnicity]\n",
    "        \n",
    "        # multiply the two together and return\n",
    "        return like_gender * like_ethnicity\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make our hypotheses and input them as tuples into the Movie class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genders = range(0,2)\n",
    "ethnicities = range(0,5)\n",
    "pairs = [(gender, ethnicity) for gender in genders for ethnicity in ethnicities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided that we are picking a random person in the United states. So, we can use population demographics of the United States as an informed prior. We will assume that the United States is 50% male and 50% female. Population percent is defined in the order which we enumerate ethnicities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0.3185\n",
      "(0, 1) 0.061\n",
      "(0, 2) 0.0815\n",
      "(0, 3) 0.0235\n",
      "(0, 4) 0.015500000000000002\n",
      "(1, 0) 0.3185\n",
      "(1, 1) 0.061\n",
      "(1, 2) 0.0815\n",
      "(1, 3) 0.0235\n",
      "(1, 4) 0.015500000000000002\n"
     ]
    }
   ],
   "source": [
    "population_percent = [63.7, 12.2, 16.3, 4.7, 3.1, 63.7, 12.2, 16.3, 4.7, 3.1]\n",
    "\n",
    "for i in range(len(population_percent)):\n",
    "    movie[pairs[i]] = population_percent[i]\n",
    "\n",
    "movie.Normalize()\n",
    "movie.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next update with the two movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1969.1499999999999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.Update('Inside Out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0.4017743696518802\n",
      "(0, 1) 0.021374704821877456\n",
      "(0, 2) 0.03046187441281771\n",
      "(0, 3) 0.004940710458827413\n",
      "(0, 4) 0.0014483406545971614\n",
      "(1, 0) 0.4716481730695985\n",
      "(1, 1) 0.02509204479089962\n",
      "(1, 2) 0.0357595917020034\n",
      "(1, 3) 0.005799964451666963\n",
      "(1, 4) 0.0017002259858314502\n"
     ]
    }
   ],
   "source": [
    "movie.Normalize()\n",
    "movie.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that a random person has seen Inside Out, the probability that the person is both female and Asian is .58%. Interestingly, when we update our hypotheses with our data, the the chance that the randomly selected person is caucasian goes up to 87%. It seems that our model just increases the chance that the randomly selected person is caucasian after seeing a movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation:  \n",
    "To make ourselves convinced that model is working properly, what happens if we just look at gender data. We know that 54% of people who saw inside out were female. So, if we sum together the female audience, we should get 54%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5399999999999999\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for pair in pairs:\n",
    "    if pair[0] == 1:\n",
    "        total += movie[pair]\n",
    "        \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parking meter theft\n",
    "\n",
    "From DASL(http://lib.stat.cmu.edu/DASL/Datafiles/brinkdat.html)\n",
    "\n",
    ">The variable CON in the datafile Parking Meter Theft represents monthly parking meter collections by the principle contractor in New York City from May 1977 to March 1981. In addition to contractor collections, the city made collections from a number of \"control\" meters close to City Hall. These are recorded under the varia- ble CITY. From May 1978 to April 1980 the contractor was Brink's. In 1983 the city presented evidence in court that Brink's employees has been stealing parking meter moneys - delivering to the city less than the total collections. The court was satisfied that theft has taken place, but the actual amount of shortage was in question. Assume that there was no theft before or after Brink's tenure and estimate the monthly short- age and its 95% confidence limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our data from the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CON</th>\n",
       "      <th>CITY</th>\n",
       "      <th>BRINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2224277</td>\n",
       "      <td>6729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1892672</td>\n",
       "      <td>5751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1468074</td>\n",
       "      <td>6711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1618966</td>\n",
       "      <td>7069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1509195</td>\n",
       "      <td>7134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIME      CON  CITY  BRINK\n",
       "0     1  2224277  6729      0\n",
       "1     2  1892672  5751      0\n",
       "2     3  1468074  6711      0\n",
       "3     4  1618966  7069      0\n",
       "4     5  1509195  7134      0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('parking.csv', skiprows=17, delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to normalize the CON (contractor) collections by the amount gathered by the CITY. This will give us a ratio of contractor collections to city collections. If we just use the raw contractor collections, fluctuations throughout the months could mislead us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['RATIO'] = df['CON'] / df['CITY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets see what the means of the RATIO data compare between the general contractors and BRINK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 244.681143201\n",
      "1 229.583858011\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('BRINK')\n",
    "for name, group in grouped:\n",
    "    print(name, group.RATIO.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for a dollar gathered by the city, general contractors report 244.7 dollars while BRINK only reports 230 dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit the data to a Normal class to compute the likelihood of a sameple from the normal distribution. This is a similar process to what we did in the improved reading ability problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class Normal(Suite, Joint):\n",
    "    \n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"\n",
    "        \n",
    "        data: sequence of test scores\n",
    "        hypo: mu, sigma\n",
    "        \"\"\"\n",
    "        mu, sigma = hypo\n",
    "        likes = norm.pdf(data, mu, sigma)\n",
    "        return np.prod(likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate a bunch of prior distributions for `mu` and `sigma`. These will be generated uniformly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mus = np.linspace(20, 80, 101)\n",
    "sigmas = np.linspace(5, 30, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use itertools.product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "control = Normal(product(mus, sigmas))\n",
    "data = df[df.BRINK=='1'].RATIO\n",
    "control.Update(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
